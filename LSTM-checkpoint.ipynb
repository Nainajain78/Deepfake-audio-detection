{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2d1307d-1b8e-4a2f-b308-f1417695417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\91979\\anaconda3\\lib\\site-packages (from lazy_loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\91979\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91979\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.5/1.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Installing collected packages: soxr, audioread, soundfile, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.11.0 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.callbacks.ModelCheckpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model, layers, models, callbacks\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mModelCheckpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Reshape, MaxPooling2D, Dropout, Conv2D, MaxPool2D, Flatten, Input, LSTM\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.callbacks.ModelCheckpoint'"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import IPython\n",
    "import json\n",
    "from scipy.io import wavfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer, LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from keras import Model, layers, models, callbacks\n",
    "from keras.callbacks.ModelCheckpoint import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, MaxPooling2D, Dropout, Conv2D, MaxPool2D, Flatten, Input, LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaaa494-92d4-4a19-9854-6cb4d317bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = \"KAGGLE/AUDIO/REAL\"\n",
    "fake_path = \"KAGGLE/AUDIO/FAKE\"\n",
    "json_path = \"KAGGLE/deep-voice-deepfake-voice-recognition-metadata.json\"\n",
    "csv_path = \"KAGGLE/DATASET-balanced.csv\"\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df['LABEL'] = df['LABEL'].apply(lambda x: 1 if x == 'REAL' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1421c56-15bd-44ad-a323-546ff692c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, sr, start_time, duration, label, id, time):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path, sr=sr, offset=start_time, duration=duration)\n",
    "    \n",
    "    # Extract features\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n",
    "    rms = np.mean(librosa.feature.rms(y=y), axis=1)\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr), axis=1)\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr), axis=1)\n",
    "    rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr), axis=1)\n",
    "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=y), axis=1)\n",
    "    \n",
    "    # Extract all 20 MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)  # Mean of all MFCC coefficients\n",
    "\n",
    "    # Combine all features into one vector (8 base features + 20 MFCCs)\n",
    "    features = np.concatenate([\n",
    "        [np.mean(chroma_stft)], [np.mean(rms)], [np.mean(spectral_centroid)],\n",
    "        [np.mean(spectral_bandwidth)], [np.mean(rolloff)], \n",
    "        [np.mean(zero_crossing_rate)], mfcc_mean, [label], [id], [time]\n",
    "    ])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795e78e-9abf-4a05-9b5c-9267a82b3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seconds = 10 \n",
    "num_features = 29\n",
    "num_total_segments = 11000\n",
    "features = np.zeros((1, num_features))\n",
    "\n",
    "file_index = 0\n",
    "id = 0\n",
    "\n",
    "for filename in os.listdir(real_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        wav_file_path = os.path.join(real_path, filename)  # Ensure correct path\n",
    "        duration = librosa.get_duration(filename=wav_file_path)\n",
    "        max_segments = int(duration // num_seconds)  # Max number of 10-second segments we can extract\n",
    "        # iterate through each segment\n",
    "        for i in range(max_segments - 1):\n",
    "            start_time = i * num_seconds\n",
    "            for time in range(num_seconds):\n",
    "                new_features  = extract_features(wav_file_path, 22050, start_time + time, 1, 1, id, time)\n",
    "                features = np.concatenate((features, new_features.reshape(1, 29)), axis=0)\n",
    "                file_index += 1\n",
    "        id += 1\n",
    "\n",
    "\n",
    "for filename in os.listdir(fake_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        wav_file_path = os.path.join(fake_path, filename)  # Ensure correct path\n",
    "        duration = librosa.get_duration(filename=wav_file_path)\n",
    "        max_segments = int(duration // num_seconds)  # Max number of 10-second segments we can extract\n",
    "        # iterate through each segment\n",
    "        for i in range(max_segments - 1):\n",
    "            start_time = i * num_seconds\n",
    "            for time in range(num_seconds):\n",
    "                new_features  = extract_features(wav_file_path, 22050, start_time + time, 1, 0, id, time)\n",
    "                features = np.concatenate((features, new_features.reshape(1, 29)), axis=0)\n",
    "                file_index += 1\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f222e5-455d-4b4e-966a-910d16cda573",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = ['chroma_stft', 'rms', 'spectral_centroid', 'spectral_bandwidth', \n",
    "                'rolloff', 'zero_crossing_rate']\n",
    "mfcc_columns = [f'mfcc{i+1}' for i in range(20)]\n",
    "columns = base_columns + mfcc_columns + ['label', 'id', 'time']\n",
    "\n",
    "df = pd.DataFrame(features, columns=columns)\n",
    "df.to_csv('10_seconds_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da371b7-6bd0-4cb0-a107-21ffcb678b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c151e-64d1-40d0-a8df-05df6915c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_correlation = df.corr()['label'].drop('label').drop('id')\n",
    "correlation = label_correlation.abs().to_frame().T\n",
    "correlation = correlation.sort_values(by=correlation.index[0], axis=1, ascending=True)\n",
    "\n",
    "plt.figure(figsize=(20, 1))\n",
    "ax = sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Absolute Correlation with label\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704e86e-895e-446f-a196-0bb06d7fe459",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in columns:\n",
    "    if var == 'label' or var == 'id' or var == 'time':\n",
    "        continue\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n",
    "    sns.histplot(data=df, x=var, hue='label', kde=True, stat='count', common_norm=False)\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'Distribution of {var} for Real and Fake Labels')\n",
    "    plt.legend(title='LABEL')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ffc6d-9cb7-47a6-befa-8e2e760f19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df['LABEL'] = df['LABEL'].apply(lambda x: 1 if x == 'REAL' else 0)\n",
    "\n",
    "y = df['LABEL']\n",
    "X = df.drop(columns=['LABEL'])\n",
    "\n",
    "seed = 2002513\n",
    "xtr, xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18824c-02fb-4bab-a2d4-2b6676577c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(xtr, ytr)\n",
    "\n",
    "y_pred = model.predict(xte)\n",
    "accuracy = accuracy_score(yte, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1237d221-b45e-48c1-8037-33e947a9ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "xtr_scaled = scaler.fit_transform(xtr)\n",
    "xte_scaled = scaler.transform(xte)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(xtr_scaled, ytr)\n",
    "y_pred = model.predict(xte_scaled)\n",
    "accuracy = accuracy_score(yte, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63adb260-b4c2-4a02-9fd4-86473b16602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('10_seconds_full.csv')\n",
    "\n",
    "y = df['label']\n",
    "X = df.drop(columns=['label','id', 'time'])\n",
    "\n",
    "seed = 2002513\n",
    "xtr, xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtr_scaled = scaler.fit_transform(xtr)\n",
    "xte_scaled = scaler.transform(xte)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(xtr_scaled, ytr)\n",
    "y_pred = model.predict(xte_scaled)\n",
    "accuracy = accuracy_score(yte, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ef8d3-48a9-4b66-b84f-77a1c63fee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1 / (1+np.exp(-X))\n",
    "\n",
    "def tanh(X):\n",
    "    return (np.exp(X) - np.exp(-X)) / (np.exp(X) + np.exp(-X))\n",
    "\n",
    "def softmax(X):\n",
    "    exp_X = np.exp(X)\n",
    "    exp_X_sum = np.sum(exp_X, axis=1).reshape(-1, 1)\n",
    "    exp_X = exp_X / exp_X_sum\n",
    "    return exp_X\n",
    "\n",
    "def tanh_derivative(X):\n",
    "    return 1-(X**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038bd68-d763-443d-aa02-1ff733c60ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_units, hidden_units, output_units):\n",
    "    mean = 0\n",
    "    std = 0.01    \n",
    "    \n",
    "    forget_gate_weights = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n",
    "    input_gate_weights_percent  = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n",
    "    input_gate_weights_memory  = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n",
    "    output_gate_weights = np.random.normal(mean,std,(input_units+hidden_units,hidden_units))\n",
    "\n",
    "\n",
    "    forget_gate_bias = np.random.normal(mean,std,(1, hidden_units))\n",
    "    input_gate_percent_bias = np.random.normal(mean,std,(1, hidden_units))\n",
    "    input_gate_memory_bias = np.random.normal(mean,std,(1, hidden_units))\n",
    "    output_gate_bias = np.random.normal(mean,std,(1, hidden_units))\n",
    "    \n",
    "    hidden_output_weights = np.random.normal(mean,std,(hidden_units,output_units))\n",
    "    \n",
    "    parameters = dict()\n",
    "    parameters['fgw'] = forget_gate_weights\n",
    "    parameters['igpw'] = input_gate_weights_percent\n",
    "    parameters['igmw'] = input_gate_weights_memory\n",
    "    parameters['ogw'] = output_gate_weights\n",
    "\n",
    "    parameters['fgb'] = forget_gate_bias\n",
    "    parameters['igpb'] = input_gate_percent_bias\n",
    "    parameters['igmb'] = input_gate_memory_bias\n",
    "    parameters['ogb'] = output_gate_bias\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e3a61-07e7-451f-91f4-c72bef37fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(parameters, short_term_matrix, long_term_matrix, input_matrix):\n",
    "    fgw = parameters['fgw']\n",
    "    igpw = parameters['igpw']\n",
    "    igmw = parameters['igmw']\n",
    "    ogw = parameters['ogw']\n",
    "    \n",
    "    \n",
    "    fgb = parameters['fgb']\n",
    "    igpb = parameters['igpb']\n",
    "    igmb = parameters['igmb']\n",
    "    ogb = parameters['ogb']\n",
    "\n",
    "    # concatenate input and short term memory matrix\n",
    "    concat_dataset = np.concatenate((short_term_matrix, input_matrix), axis=1)\n",
    "\n",
    "    # forget gate\n",
    "    fa = np.matmul(concat_dataset, fgw)\n",
    "    fa = np.add(fa, fgb)\n",
    "    forget_gate_output = sigmoid(fa)\n",
    "\n",
    "    # input gate\n",
    "    input_potential = np.matmul(concat_dataset, igpw)\n",
    "    input_potential = np.add(input_potential, igpb)\n",
    "    input_potential = sigmoid(input_potential)\n",
    "\n",
    "    input_memory = np.matmul(concat_dataset, igmw)\n",
    "    input_memory = np.add(input_memory, igmb)\n",
    "    input_memory = tanh(input_memory)\n",
    "\n",
    "    input_gate_output = input_potential * input_memory\n",
    "\n",
    "    # update long term memory\n",
    "    long_term_memory = np.multiply(long_term_matrix, forget_gate_output)\n",
    "    long_term_memory = np.add(long_term_memory, input_gate_output)\n",
    "\n",
    "    # output gate\n",
    "    output_percent = np.matmul(concat_dataset, ogw)\n",
    "    output_percent = np.add(output_percent, ogb)\n",
    "    output_percent = sigmoid(output_percent)\n",
    "\n",
    "    output_potential = tanh(long_term_memory)\n",
    "\n",
    "    # update short term memory\n",
    "    short_term_memory = np.multiply(output_percent, output_potential)\n",
    "\n",
    "    # return long and short term memory\n",
    "    return long_term_memory, short_term_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb57505-ad9a-460e-8501-10e5e4f8f43e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m output_units \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Output units (optional for full model)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize the parameters\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m parameters \u001b[38;5;241m=\u001b[39m init_params(input_units, hidden_units, output_units)\n\u001b[0;32m     10\u001b[0m input_matrix \u001b[38;5;241m=\u001b[39m xtr\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Create a sample short-term memory (previous hidden state, [1, 128])\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'init_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming the input size and hidden units for the LSTM\n",
    "input_units = 26  # Number of features in the input\n",
    "hidden_units = 128  # Number of LSTM hidden units\n",
    "output_units = 1  # Output units (optional for full model)\n",
    "\n",
    "\n",
    "# Initialize the parameters\n",
    "parameters = init_params(input_units, hidden_units, output_units)\n",
    "\n",
    "input_matrix = xtr\n",
    "# Create a sample short-term memory (previous hidden state, [1, 128])\n",
    "short_term_matrix = np.random.randn(20, hidden_units)  # Short-term memory from the previous time step\n",
    "\n",
    "# Create a sample long-term memory (previous cell state, [1, 128])\n",
    "long_term_matrix = np.random.randn(20, hidden_units)  # Long-term memory from the previous time step\n",
    "\n",
    "# Run the LSTM cell\n",
    "new_long_term_memory, new_short_term_memory = lstm_cell(parameters, short_term_matrix, long_term_matrix, input_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98481b5e-0e82-441b-906b-f135ed39e59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9093a9c-4501-4acd-ade0-646e02b1e74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397916ca-5a12-4526-b1d6-3872b796a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3a699-8241-4bb1-bd6f-2c3553284a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1e53d3-7289-4b40-ba68-d334e45ba515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d5858-d614-44ef-ac1a-e261ef4f91a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16920f21-eee2-4577-bb50-8d5882d7453d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8123c1fb-b8a3-4f3b-b36b-fe122e6a4cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ca3fd-6f44-4e8c-b0c9-2b321d630d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
